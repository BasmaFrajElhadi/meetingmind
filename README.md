![MeetingMind Logo](reports/figures/logo.png)

# ðŸ’­ MeetingMind â€“ Smart AI Meeting Assistant

## ðŸ“Œ Project Overview

**MeetingMind** is an intelligent AI assistant designed to transform your meetings into structured knowledge. It helps teams and professionals automatically transcribe, summarize, extract tasks, analyze sentiment, detect topics, and provide research insights â€” all from raw meeting audio.  

**Audience:**  
- Business teams and project managers  
- Remote work teams  
- Researchers and analysts  
- Anyone who wants to save time by automating meeting documentation  

**How it Works:**  
1. upload your meeting audio.  
2. AI transcribes the conversation using Whisper.  
3. Generate structured summaries, tasks, and sentiment insights using DeepSeek-V3.  
4. Extract the meetingâ€™s primary topic, then leverage Groq to gather relevant online insights and research based on that topic.
5. Review everything through an intuitive Streamlit dashboard.  

![Workflow](reports/figures/meeting_analysis_workflow.png)

## âœ¨ Features

- **Audio Transcription:** Accurate conversion of speech to text using Whisper.  
- **Meeting Summarization:** Structured summaries with key decisions and discussion points.  
- **Task Extraction:** Identify actionable tasks, responsible persons, and deadlines.  
- **Sentiment Analysis:** Detect emotional tone and highlight key emotions.  
- **Topic Extraction:** Quickly identify the main topic of the meeting.  
- **Research Assistant:** Fetch relevant, trending, and factual online information.  
- **Interactive Dashboard:** Streamlit interface to manage audio, view transcripts, summaries, tasks, sentiment, and research.  

## ðŸ§  Tech Stack

MeetingMind is built using a modern, high-performance AI stack designed for fast processing, accurate transcription, and powerful meeting insights.

### **Core Technologies**

* **Python** â€” Primary language powering the backend, processing pipeline, and integrations
* **Whisper** â€” High-accuracy speech-to-text model used for audio transcription
* **DeepSeek-V3** â€” Handles advanced summarization, action-item extraction, and sentiment analysis
* **Groq API** â€” Ultra-fast inference used for web-based research
* **Streamlit** â€” Interactive dashboard for uploading audio, reviewing transcripts, and exploring insights

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
![Whisper](https://img.shields.io/badge/Whisper-Transcription-orange?logo=openai&logoColor=white)
![DeepSeek](https://img.shields.io/badge/DeepSeek-V3-brightgreen)
![Groq](https://img.shields.io/badge/Groq-API-EA4335?logo=lightning&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-ff4b4b?logo=streamlit&logoColor=white)

## ðŸ“‚ Folder Structure

```
meetingmind/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dashboard/            # Streamlit app and UI components
â”‚   â”‚   â””â”€â”€ app.py            # Main entry point for the dashboard
â”‚   â”‚   â””â”€â”€ components.py            
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                # Audio enhancement
â”‚   â”‚   â””â”€â”€ enhancer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ transcription/        # Whisper transcription & utilities
â”‚   â”‚   â”œâ”€â”€ base_transcriber.py
â”‚   â”‚   â””â”€â”€ whisper_transcriber.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/             # Summarization, task extraction, sentiment analysis
â”‚   â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”‚   â”œâ”€â”€ task_extractor.py
â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ research/             # Topic extraction and web search modules
â”‚   â”‚   â”œâ”€â”€ topic_extractor.py
â”‚   â”‚   â””â”€â”€ web_searcher.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                  # LLM clients (DeepSeek, Gemini, etc.)
â”‚   â”‚   â”œâ”€â”€ base_llm_client.py
â”‚   â”‚   â”œâ”€â”€ deepseek_client.py
â”‚   â”‚   â””â”€â”€ gemini_client.py
â”‚   â”‚   â””â”€â”€ langchain_google_client.py
â”‚   â”‚
â”‚   â”œâ”€â”€ handlers/             # Error handling, utility decorators, logging
â”‚   â”‚   â””â”€â”€ error_handler.py
â”‚   â”‚
â”‚   â””â”€â”€ prompt_engineering/   # Prompt templates and loader utilities
â”‚       â””â”€â”€ templates.py
â”‚
â”œâ”€â”€ data/                     # Audio, transcripts, and analysis outputs
â”‚   â”œâ”€â”€ transcripts/          
â”‚   â””â”€â”€ analysis_outputs/     
â”‚       â”œâ”€â”€ summaries/        
â”‚       â”œâ”€â”€ tasks/            
â”‚       â””â”€â”€ sentiment/        
â”‚
â”œâ”€â”€ config/                   # Model and prompt configurations
â”‚   â”œâ”€â”€ models.yaml           
â”‚   â””â”€â”€ prompts.yaml           
â”‚
â”œâ”€â”€ examples/                 # Example audio files and transcripts
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks for experiments and demos
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ .env                      # Environment variables (API keys)
```

## ðŸ›  Getting Set Up

Follow these steps to get **MeetingMind â€“ Smart AI Meeting Assistant** up and running on your local machine.

### 1. **Clone the repository**

```bash
git clone https://github.com/BasmaFrajElhadi/meetingmind.git
cd meetingmind
```
### 2. **Install dependencies**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 3. **Set up environment variables**

Create a `.env` file in the project root with your API keys and configuration:

```env
OPENROUTER_API_KEY=your_openrouter_api_key
GROQ_API_KEY=your_groq_api_key
```

> ðŸ”‘ Required for AI services.

### 5. **Run the Streamlit dashboard**

```bash
streamlit run src/dashboard/app.py
```

## ðŸ“œ License

**Apache License 2.0** â€“ Free to use, modify, and build upon with proper attribution.